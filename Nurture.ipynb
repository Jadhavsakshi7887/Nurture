{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a0et0lNELKx3"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_DIR = './titanic_output'\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "CSV_PATH = '/content/data.csv'\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    raise FileNotFoundError(f\"{CSV_PATH} not found in current directory. Download from Kaggle and place it here.\")\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print('Loaded dataset shape:', df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkakDDB6P95e",
        "outputId": "8b895252-284e-4ac7-92ec-0f37ab093a5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset shape: (891, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# columns useful for prediction\n",
        "keep_cols = ['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\n",
        "df = df[keep_cols].copy()\n",
        "\n",
        "print(df.head())\n",
        "print('\\nMissing values per column:\\n', df.isnull().sum())\n",
        "\n",
        "# Handle missing values\n",
        "num_imputer = SimpleImputer(strategy='median')\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "df['Age'] = num_imputer.fit_transform(df[['Age']])\n",
        "df['Fare'] = num_imputer.fit_transform(df[['Fare']])\n",
        "df['Embarked'] = cat_imputer.fit_transform(df[['Embarked']]).ravel()\n",
        "\n",
        "# Encode categorical variables\n",
        "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1}).astype(int)\n",
        "emb_ohe = pd.get_dummies(df['Embarked'], prefix='Emb')\n",
        "df = pd.concat([df.drop(columns=['Embarked']), emb_ohe], axis=1)\n",
        "\n",
        "# Features and target\n",
        "target = 'Survived'\n",
        "feature_cols = [c for c in df.columns if c != target]\n",
        "\n",
        "# Standardize numerical features: Age, Fare, SibSp, Parch, Pclass\n",
        "num_cols = ['Age','Fare','SibSp','Parch','Pclass']\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC1E6HlhQDMT",
        "outputId": "0f1f6509-ce80-44aa-9e1f-d4f1a2c19432"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
            "0         0       3    male  22.0      1      0   7.2500        S\n",
            "1         1       1  female  38.0      1      0  71.2833        C\n",
            "2         1       3  female  26.0      0      0   7.9250        S\n",
            "3         1       1  female  35.0      1      0  53.1000        S\n",
            "4         0       3    male  35.0      0      0   8.0500        S\n",
            "\n",
            "Missing values per column:\n",
            " Survived      0\n",
            "Pclass        0\n",
            "Sex           0\n",
            "Age         177\n",
            "SibSp         0\n",
            "Parch         0\n",
            "Fare          0\n",
            "Embarked      2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save prepared dataset\n",
        "prepared_path = os.path.join(OUT_DIR,'titanic_prepared.csv')\n",
        "df.to_csv(prepared_path, index=False)\n",
        "print('Saved prepared dataset to', prepared_path)\n",
        "\n",
        "report_lines = []\n",
        "report_lines.append('# Titanic Dataset - EDA & Preprocessing Report')\n",
        "report_lines.append('\\n## Part 1: Data Understanding & Preprocessing')\n",
        "report_lines.append('\\nColumns used: ' + ', '.join(feature_cols) + '\\n')\n",
        "\n",
        "# Summary stats for numeric columns\n",
        "stats = df[num_cols].agg(['mean','median','std']).T\n",
        "report_lines.append('\\n### Numeric feature statistics')\n",
        "report_lines.append(stats.to_markdown())\n",
        "\n",
        "# Outlier detection using IQR for Age and Fare\n",
        "outlier_dict = {}\n",
        "for col in ['Age','Fare']:\n",
        "    q1 = df[col].quantile(0.25)\n",
        "    q3 = df[col].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower = q1 - 1.5*iqr\n",
        "    upper = q3 + 1.5*iqr\n",
        "    count = ((df[col] < lower) | (df[col] > upper)).sum()\n",
        "    outlier_dict[col] = {'lower':float(lower),'upper':float(upper),'num_outliers':int(count)}\n",
        "\n",
        "report_lines.append('\\n### Outlier info (IQR method)')\n",
        "report_lines.append(pd.DataFrame(outlier_dict).T.to_markdown())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkRTi9QgQJkI",
        "outputId": "c93e2bba-1e19-432d-ba84-c71b88404caf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved prepared dataset to ./titanic_output/titanic_prepared.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizations\n",
        "# 1) Histogram: Age\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.hist(df['Age'], bins=30)\n",
        "plt.title('Histogram: Age (standardized)')\n",
        "plt.xlabel('Age (standardized)')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "hist_path = os.path.join(OUT_DIR,'hist_age.png')\n",
        "plt.savefig(hist_path)\n",
        "plt.close()\n",
        "\n",
        "# 2) Scatter: Age vs Fare colored by Survived\n",
        "plt.figure(figsize=(7,5))\n",
        "colors = df['Survived'].map({0:'red',1:'green'})\n",
        "plt.scatter(df['Age'], df['Fare'], c=colors, alpha=0.6)\n",
        "plt.title('Scatter: Age vs Fare (color=Survived)')\n",
        "plt.xlabel('Age (standardized)')\n",
        "plt.ylabel('Fare (standardized)')\n",
        "plt.tight_layout()\n",
        "scatter_path = os.path.join(OUT_DIR,'scatter_age_fare.png')\n",
        "plt.savefig(scatter_path)\n",
        "plt.close()\n",
        "\n",
        "# 3) Correlation heatmap\n",
        "corr = df.corr()\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(corr, interpolation='nearest', cmap='coolwarm')\n",
        "plt.xticks(range(len(corr.columns)), corr.columns, rotation=45, ha='right')\n",
        "plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "plt.colorbar()\n",
        "plt.title('Correlation matrix')\n",
        "plt.tight_layout()\n",
        "heatmap_path = os.path.join(OUT_DIR,'corr_heatmap.png')\n",
        "plt.savefig(heatmap_path)\n",
        "plt.close()\n",
        "\n",
        "report_lines.append('\\nSaved visualizations:')\n",
        "report_lines.append(f'- {hist_path}')\n",
        "report_lines.append(f'- {scatter_path}')\n",
        "report_lines.append(f'- {heatmap_path}\\n')\n"
      ],
      "metadata": {
        "id": "10ysInCaQTqX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "report_lines.append('\\n## Part 3: Model Building')\n",
        "X = df[feature_cols]\n",
        "y = df[target]\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)\n",
        "\n",
        "# Model 1: Logistic Regression\n",
        "lr = LogisticRegression(max_iter=500)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Model 2: Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "Jo1jqmydQdvz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluation function\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def eval_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        'accuracy': float(accuracy_score(y_true, y_pred)),\n",
        "        'precision': float(precision_score(y_true, y_pred, zero_division=0)),\n",
        "        'recall': float(recall_score(y_true, y_pred, zero_division=0)),\n",
        "        'f1': float(f1_score(y_true, y_pred, zero_division=0)),\n",
        "        'confusion_matrix': confusion_matrix(y_true, y_pred).tolist()\n",
        "    }\n",
        "\n",
        "metrics_lr = eval_metrics(y_test, y_pred_lr)\n",
        "metrics_rf = eval_metrics(y_test, y_pred_rf)\n",
        "\n",
        "report_lines.append('\\n### Baseline performance (before tuning)')\n",
        "report_lines.append('\\n**Logistic Regression:**')\n",
        "report_lines.append(str(metrics_lr))\n",
        "report_lines.append('\\n**Random Forest:**')\n",
        "report_lines.append(str(metrics_rf))\n",
        "\n",
        "#  confusion matrix image for RF\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.imshow(confusion_matrix(y_test,y_pred_rf))\n",
        "plt.title('Confusion Matrix - Random Forest (before tuning)')\n",
        "plt.colorbar()\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "cm_before_path = os.path.join(OUT_DIR,'cm_rf_before.png')\n",
        "plt.savefig(cm_before_path)\n",
        "plt.close()\n",
        "\n",
        "report_lines.append('\\n## Part 4: Optimization (GridSearchCV)')\n",
        "param_grid = {\n",
        "    'n_estimators': [50,100,200],\n",
        "    'max_depth': [None, 5, 8],\n",
        "    'min_samples_split': [2,4]\n",
        "}\n",
        "gs = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=4, scoring='accuracy', n_jobs=-1)\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "best_rf = gs.best_estimator_\n",
        "print('Best params:', gs.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMMflmSgQrvY",
        "outputId": "a4356866-e323-4a3a-9025-8fba6c51d95b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'max_depth': None, 'min_samples_split': 4, 'n_estimators': 50}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate tuned model\n",
        "y_pred_best = best_rf.predict(X_test)\n",
        "metrics_best = eval_metrics(y_test, y_pred_best)\n",
        "report_lines.append('\\nBest params: ' + str(gs.best_params_))\n",
        "report_lines.append('\\nPerformance after tuning:')\n",
        "report_lines.append(str(metrics_best))\n",
        "\n",
        "# confusion matrix after tuning\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.imshow(confusion_matrix(y_test,y_pred_best))\n",
        "plt.title('Confusion Matrix - Random Forest (after tuning)')\n",
        "plt.colorbar()\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "cm_after_path = os.path.join(OUT_DIR,'cm_rf_after.png')\n",
        "plt.savefig(cm_after_path)\n",
        "plt.close()\n",
        "\n",
        "# Compare improvements\n",
        "improvements = {\n",
        "    'accuracy_before': metrics_rf['accuracy'],\n",
        "    'accuracy_after': metrics_best['accuracy'],\n",
        "    'f1_before': metrics_rf['f1'],\n",
        "    'f1_after': metrics_best['f1']\n",
        "}\n",
        "report_lines.append('\\nImprovements (Random Forest):')\n",
        "report_lines.append(str(improvements))\n",
        "\n",
        "# Save tuned model\n",
        "model_path = os.path.join(OUT_DIR,'best_random_forest.joblib')\n",
        "joblib.dump(best_rf, model_path)\n",
        "report_lines.append('\\nSaved tuned model to: ' + model_path)"
      ],
      "metadata": {
        "id": "6ShzF4QZQ3zh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/data.csv')\n",
        "\n",
        "keep_cols = ['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Survived']\n",
        "df = df[keep_cols].copy()\n",
        "\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "df['Sex'] = df['Sex'].map({'male':0, 'female':1})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_q1ble-Q_Ah",
        "outputId": "608f2d1a-f755-48c0-ee20-ddb19cf27054"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1382533630.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
            "/tmp/ipython-input-1382533630.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
            "/tmp/ipython-input-1382533630.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = ['Pclass','Sex','Age','SibSp','Parch','Fare']\n",
        "mean_vals = df[num_cols].mean().values\n",
        "std_vals = df[num_cols].std().values\n"
      ],
      "metadata": {
        "id": "Z43KUZeeUqFV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def scale_numeric(new_input):\n",
        "    return (np.array(new_input) - mean_vals) / std_vals\n"
      ],
      "metadata": {
        "id": "GynO1cYlVGL1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load trained model\n",
        "model = joblib.load('/content/titanic_output/best_random_forest.joblib')\n",
        "\n",
        "# Pclass=3, Sex=female, Age=29, SibSp=0, Parch=0, Fare=15.0, Embarked=S\n",
        "num_input = scale_numeric([3, 1, 29, 0, 0, 15.0])\n",
        "\n",
        "# One-hot encode Embarked\n",
        "emb_dict = {'C':[1,0,0], 'Q':[0,1,0], 'S':[0,0,1]}\n",
        "emb_input = np.array(emb_dict['S'])\n",
        "\n",
        "# Combine numeric + categorical\n",
        "X_new = np.hstack([num_input, emb_input]).reshape(1,-1)\n",
        "\n",
        "# Predict\n",
        "pred = model.predict(X_new)\n",
        "print('Prediction:', 'Survived' if pred[0]==1 else 'Did not survive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnVhniu2VHl8",
        "outputId": "084c6b28-724b-40b0-fc86-9c9ae4308ba1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Survived\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7cu3vhxSVI5O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}